% (This is included by thesis.tex; you do not latex it by itself.)

\begin{abstract}

% Pro-tip: to facilitate version control diffing, it can be easier to make each sentence its own line so then you can just tell which sentences change.
% Or you can try to limit line length (but that seems like too much of a pain).
% EG - Abstract should focus on describing the work you did, to make clear what are the unique contributions, and what are the major outcome and findings. 

Graphics processing units, or GPUs, have gradually increased in computational power from the small, job-specific boards of the early 1990s to the programmable powerhouses of today. Compared to more common central processing units, or CPUs, GPUs have a higher aggregate memory bandwidth, much higher floating-point operations per second (FLOPS), and lower energy consumption per FLOP. Because one of the main obstacles in exascale computing is power consumption, many new supercomputing platforms are gaining much of their computational capacity by incorporating GPUs into their compute nodes. Since CPU-optimized parallel algorithms are not directly portable to GPU architectures (or at least not without losing substantial performance gain), transport codes need to be rewritten to execute efficiently on GPUs. Unless this is done, reactor simulations cannot take full advantage of these new supercomputers. 

WARP, which can stand for ``Weaving All the Random Particles,'' is a three-dimensional (3D) continuous energy Monte Carlo neutron transport code that has been developed at UC Berkeley as a first attempt to efficiently implement a continuous energy Monte Carlo neutron transport algorithm on a GPU.  WARP accelerates Monte Carlo simulations while preserving the benefits of using the Monte Carlo Method, namely, very few physical and geometrical simplifications.  WARP is able to calculate multiplication factors, flux tallies, and fission source distributions for time-independent problems, and can run in both criticality or fixed source modes.

GPUs gain computational throughput by having large single instruction, multiple data (SIMD) units, which require the same instruction to be carried out over data elements.  This is very similar to vector computers of the past, and ``event-based'' Monte Carlo algorithms have been developed to execute on these types of computers.  Event-based algorithms are those where neutron histories undergoing the same event are inserted into vectors, and when the vector is filled, it is processed by a vector unit in parallel.  After a step of transport, the vectors are no longer have data that need the same operation, so a ``shuffle'' operation is done, which moves data elements between vectors, and makes them uniform again for the next step of parallel processing.

WARP uses a similar event-based algorithm, but with some important differences.  Moving data is expensive, so WARP uses a remapping vector of pointer/index pairs to direct GPU threads to the data they need to access.  The remapping vector is sorted  by reaction type after every transport iteration using a high-efficiency parallel radix sort, which serves to keep the reaction types as contiguous as possible as well as eliminating completed histories from the transport cycle.  The sort reduces the amount of divergence in GPU ``thread blocks,'' keeps the SIMD lanes of the as full as possible, and eliminates wasting memory bandwidth to check if a neutron in the batch has been terminated or not.  Using a remapping vector means the data access pattern is irregular, but this is mitigated by using large batch sizes where the GPU can effectively hide the high cost of irregular global memory access.

WARP uses a  unionized energy grid format for storing nuclear data, since it it important for regularizing data access.  Unionizing the energy grids creates a single, universal energy grid for all cross section data, meaning a single search is needed per transport step instead of one for every isotope included in the simulation.  WARP modifies the standard implementation to reduce memory traffic.  Instead of storing a matrix of pointers indexed by reaction type and energy, WARP stores three matrices.  The first contains cross section values, the second pointers to angular distributions, and a third for pointers to energy distributions.  This linked list type of layout increases memory usage, but lowers the number of data loads that are needed to determine a reaction by eliminating a pointer load to find a cross section value.

Optimized, high-performance libraries are also used by WARP wherever possible.  The CUDA performance primitives (CUDPP) library is used to perform the parallel reductions, sorts and sums, the CURAND library is used to seed the linear congruential random number generators, and the OptiX ray tracing framework is used for geometry representation.  OptiX is ...  WARP also performs material and cell number queries with OptiX by using a point-in-polygon like algorithm.

In the initial benchmarking of the best-performing mode, in which $10^6$ source neutrons per criticality batch are used, WARP is capable of delivering results that are nearly identical to MCNP 6.1 and Serpent 2.1.18, but with run times that are 11-82 times lower.  On average, WARP's performance on a NIVIDIA K20 is equivalent approximately 45 AMD Opteron 6172 CPU cores.  Larger batches are typically better on the GPU, but memory limitations of the card restricted batch size to $10^6$ source neutrons.

WARP has shown that GPUs are an effective platform for performing Monte Carlo neutron transport with continuous energy cross sections.  Currently, WARP only has limited capabilities and problems with many isotopes have not been tested, but it shows that good performance can be achieved on a GPU despite the inherently divergent program flow and sparse data access patterns.  WARP is not ready for everyday nuclear reactor calculations, but is a good platform for further development.  In it's current state, it may be a useful tool for multiplication factor searches, i.e. determining reactivity coefficients by perturbing material densities or temperatures, since these types of calculations typically do not require many tallies. 

\end{abstract}
