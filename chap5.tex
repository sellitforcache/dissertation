\chapter{Conclusions and Future Work}
\label{chap:conclusions}

%Start with a brief summary of what you have accomplished (emphasis on new elements) and in what ways you have advanced the state of the art.  enough I hope?
The WARP code developed in this work is currently the most detailed and feature-rich program in existence for performing continuous energy Monte Carlo neutron transport in general 3D geometries on GPUs.  It implements a novel adaptation of an event-based transport algorithm; loads standard data files; unionizes the nuclear data in a new, high performance way; accurately simulates each reaction type specified in the data; and uses a flexible, scalable, and optimized geometry representation.

The ultimate purpose for developing WARP was to accelerate accurate, continuous-energy neutron transport simulations in general, 3D geometries by using GPUs.  By that metric it has been successful in its mission.  It can produce results within fractions of a percent of qualified and benchmarked production codes like MCNP and Serpent.  It can produce these results 11-80 times faster, depending on problem parameters and hardware.  Along the way, useful information regarding the importance of thread divergence, neutron termination, geometric acceleration structures, and dataset size has been collected and analyzed.

WARP's secondary goal of using standard nuclear data files, running in both fixed-source and criticality-source modes, calculating multiplication factors, and producing neutron spectra have also been achieved.  Despite these milestones, WARP can only handle a single tally volume, fixed-source mode runs only marginally faster than Serpent and MCNP and produces spectra with inaccurate source values, and loading data from many isotopes has not been tested.  It also does not have routines to handle thermal scattering data or unresolved resonance tables. There is still much work to be done in testing, stabilizing WARP's execution, adding physics and features, as well as continuing to optimize algorithms for efficient GPU execution.

This initial development phase of WARP is the first step in creating a full-featured reactor simulation program that runs on GPUs.  Such an effort was needed to ensure the nuclear engineering community's codebase keeps abreast of modern programming techniques and hardware.  WARP is by no means a mature code ready to be used in everyday nuclear reactor calculations, but rather it is a good starting point for more advanced development.  

In its current state it may be a good tool for multiplication factor searches, like determining reactivity coefficients by perturbing material densities and temperatures, since these types of calculations typically do not require many flux tallies.  WARP is also useful in a workstation environment since it currently can only be run on a single GPU card and can significantly accelerate calculations where only a few CPU cores would be available otherwise.  Conversely, it is currently not good for depletion calculations since they can require many, many tallies.  This is not to say that GPUs couldn't perform depletion well, but rather that WARP is currently not suited to the task.

\section{Conclusions}

The development of WARP has led to important conclusions.  The first is that running with large datasets, and therefore a large number of threads, is important for good performance.  It was found that in some cases, moving from $10^5$ to $10^6$ neutrons per batch in criticality mode increase performance by a factor of four or more.  It is important to keep the GPU saturated with threads so it can effectively pipeline data loads.  
%WARP uses global operations to act on a large dataset of neutron histories, and there is no state continuity between kernel launches.  Therefore data must be stored in and loaded from global memory.  This makes it  important to launch as many threads as possible so the GPU can hide the large data access latencies though pipelining, especially since data access is random and non-coalesced, exacerbating the need for pipelining.  In addition to being able to hide latencies better with more active threads, using large datasets also pays for kernel launch overhead by making the computational payload large and therefore the factional cost of launching a kernel small.  This also why it is important to have most of the data loads requested immediately at the beginning of the kernel; the compute rate mainly depends on the rate at which data is fetched, so fetching it as soon as possible will provide the best performance.

The second conclusion is that remapping threads to active data is an effective way of raising the processing rate when the number of active neutrons becomes small; this also reduces thread divergence in reaction kernels.  Using a radix sort to do the remapping is effective since it segregates reactions into contiguous blocks, efficient since it can be done in place and in $O(kN)$ time, and can eliminate completed data from being accessed if slight modifications to the standard reaction number encodings are made.  

Most of the performance gain in remapping data references comes from being able to launch grids that are sized for only the active data rather than the entire dataset for both global and reaction kernels.  A non-remapping algorithm does not keep track of where active data is, and therefore must launch a grid that covers the entire dataset.  When the number of active neutrons drops below about 30\% of the initial number, the overhead and memory bandwidth cost of launching these extra threads, which only load a ``done'' bit and return, is more than the cost of performing the radix sort and edge detection.  The majority of the transport iterations occur  while there are less than 30\% of the initial neutrons left, and remapping references is usually worthwhile.

Using the NVIDIA OptiX ray tracing framework was also shown to be an effective way to handle the geometry representation in WARP.  OptiX is flexible, allows attachment of material and cell number to individual geometric primitives, can perform surface detection with a randomly-distributed and directed dataset, can incorporate the remapping vector created by a radix sort, and can do so fast enough to be used in WARP.  The acceleration structures that OptiX can automatically build over the scene geometry was the initial reason for using it, and it was determined that the BVH builder and traverser provide the best performance as does using mesh primitive instancing rather than a transform node approach.  The number of objects present in the scenes in reactors is small compared to many rending scenes, and the SBVH acceleration structure does not perform as well. This is presumably due to some additional overhead related to traversing the objects that is not offset when few objects (less than a few hundred thousand) are present in the scene.  Primitive instance provides better performance since using transform nodes requires traversing a deeper geometry tree, which also has more (redundant) data associated to it.

Further, assuming the capital prices for the GPU and CPU servers outlined in Table \ref{gpu_money} and that CPU code scales linearly, the capital price per Monte Carlo ``history power,'' or histories run per second, of a GPU is 2.8 times lower than that of a CPU on average for the tests done in this work, indicating that GPUs are a sound hardware investment for running Monte Carlo neutron transport.% I think this is stated backwards. If the price per history power is higher for GPUs we should pick CPUs. Maybe you mean history power per unit cost?  yes, OOPS!  
 This conclusion only takes the results of WARP's initial development in account, i.e.\ simple materials and a single tally.  Determining how to maintain high performance when both the number of materials and tallies are increased will be part of the future development of WARP.

\section{Future Work}

The initial goals of WARP have been completed, but there is much work still to be done if it is going to be of real use to the nuclear engineering community.  Basic functionality is currently good enough to assure the GPUs could accelerate high-fidelity Monte Carlo neutron transport calculations, which was the point of this dissertation, but many capabilities need to be expanded and ensured to scale well to large numbers of neutrons, isotopes, and geometrical zones.

The geometry is currently handled by OptiX since it provides a convenient way to obtain high-performance results, but its execution had to be coerced into providing WARP with the information it needed, namely the material number via the point-in-polygon algorithm.  The way OptiX executes this algorithm is not efficient since it must be done iteratively using OptiX's native functions instead of calculating the ordered list of intersections in a single trace.  NVIDIA is releasing ``OptiX Prime'' with OptiX 3.5 \cite{optix3.5}, which promises to provide a more ``to the metal'' ray tracing experience, and might be leveraged to provide more efficient single-traverse functionality.  OptiX could also be replaced by Rayforce \cite{rayforce}, a high-performance GPU ray tracing library developed by VSL that has this functionality built-in and is currently available free of charge for noncommercial use.

The geometry routines could also be replaced by handwritten routines that use combinatorial solid geometry like Serpent and MCNP.  This would make writing input for WARP more like what most nuclear engineers are already used to and, more importantly, could provide a potential performance increase.  A universe-based CSG representation may map very well to the GPU and may even be able to fit inside of shared memory for small numbers of surfaces.  The surfaces may also be able to be bound to texture memory, which could provide a performance boost since it automatically caches for spatial locality.  

Using an efficient CSG method would further lend itself to using Woodcock delta-tracking for the neutrons and thus getting rid of the tracing algorithms and libraries altogether.  These algorithms account for about 50\% of execution time, and WARP's performance could be doubled by making the geometry routines more efficient.  If OptiX is determined to be the best option out of these others, however, a routine would need to be developed to automatically space coincident surfaces appropriately without specific user input.

WARP's execution can also be improved.  The amount of memory required per neutron was not tracked in this initial development, much less optimized, since developing a functioning code was the main priority.  Reducing the memory needed per neutron would be highly beneficial in the sense that more concurrent neutrons could be launched using the reclaimed memory space.  Dynamic parallelism can be implemented to minimize kernel launch overhead and host-device communication in the inner transport loop.  Dynamic parallelism is a feature introduced into the NVIDA Kepler GPUs that allows kernels to be launched from kernels, and could eliminate the host needing to contain the main transport loop.  Neither CUDPP or OptiX support its use, however.  CUDPP could be replaced with newer, higher-performance libraries (e.g.\ CUB) that do support dynamic parallelism, but OptiX would have to be replaced by a handwritten kernel to perform the necessary geometric tasks.  Textures could be thoroughly investigated as they might provide better performance in tasks where their free linear interpolation and spatial caching could provide a performance boost, like in an energy grid search on a tree structure.   Alternatively, using optimized graph search libraries, like ``gunrock,'' could be used to perform the energy grid search.

WARP also currently only supports fixed-source mode in the non-remapping version as it requires popping secondary neutrons back into the active neutron pool after every iteration of the inner transport loop.  This operation is expensive since it is a global operation that must be done often.  This algorithm could be changed to be more like a criticality run, where the primary neutrons are all transported together, then the next (smaller) generation of secondary particles are transported, then the next, and so on.  This way, the pop routine is only executed in the outer loop, and could produce faster results.  Multi-GPU support should also be added so that WARP can be used effectively on computers with more than a one GPU.

If an entire overhaul of the WARP transport algorithm is feasible, using a SM-based algorithm might be investigated instead of current global one.  This type of algorithm would treat each SM as an independent processor, and would provide each a bank of neutrons to transport, as is done by Liu and Henderson \cite{tianyu,henderson}.   This way, neutron data could be stored in very fast shared memory, but using this memory space would compete with storing geometric information there.  Also, since a smaller set of neutrons could be stored, the SMs would need to communicate to determine which of the next neutrons they would take out of the global bank, or they would need to periodically rendezvous to shared source information and ensure that the distributions they use are each converged.  This type of transport algorithm would also preclude using OptiX, since it does not have SM-level functionality \cite{optix}.

Data access patterns are very important on the GPU, and there are a few straight forward modifications that could be made to WARP in the future.  The first is using Legendre expansion data for the angular dependencies of anisotropic scattering instead of using tabular data.  This method uses more computation and less data than tabular distributions, and would probably perform well on the GPU.  Since global memory comes at a premium on GPUs, an on-the-fly temperature treatment for nuclides would likely be required if more than a handful of isotopes are desired at more than one temperature.  Methods like those used in Serpent could be adapted for use on the GPU \cite{serpent}.  On-the-fly methods reduce the amount of storage needed, but they require more computation per data element loaded since the loaded value is adjusted according to the temperature of the material.  This kind of method may work well on the GPU since GPUs have a larger FLOP/byte ratio than CPUs and the additional work may cost little.  Other than the how to represent and adjust the data, an efficient way to handle situations where there are many different material and isotopes present needs to be explored.  The work done by Scudiero on porting OpenMC's macroscopic cross section processing benchmarking tool, ``xsbench,'' may elucidate this endeavor \cite{openmc,scudiero}.

%ADD:  neutron importance (cutoffs in subcritical mult), variance reduction tech, multiple tallies and reaction rates, BU, reproducibility, Shannon, debugging.  done.
WARP would gain usability if more features were incorporated as well.  Currently, WARP treats all neutrons equally, but adding neutron weight would allow many variance reduction techniques to be implemented.  Importance cutoffs could be used to terminate secondary neutrons in fixed source runs, leading to shorter runtimes; cell importances and implicit absorption could help improve tally statistics.  Developing an efficient way to include many reaction rate tallies would also make WARP useful for performing depletion analysis.  It would also be helpful for WARP to have statistical tests like Shannon entropy to ensure the fission source is fully converged before tallies and multiplication factors are accumulated.

WARP still has some bugs, and a large part of future development will be tracking them down to ensure that accurate results are produced.  Reproducibility using the same random number seeds will also be investigated to ensure consistent results can be produced and that there are no systematic errors present in WARP.  Ensuring reproducibility will also be necessary in making a test suite for WARP, so future users can have confidence in their results and future developers can know their modifications do not introduce errors into WARP.

Releasing WARP as open source software is in progress and is pending University approval.  OpenMC has opened the door for open source neutron transport codes, and WARP will hopefully follow in its footsteps.  Releasing the source openly has obvious benefits like providing potential users with a convenient and transparent way of obtaining the software, as well as allowing for valuable contributions from the community.  



