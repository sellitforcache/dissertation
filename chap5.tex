\chapter{Conclusions and Future Work}
\label{chap:conclusions}

The ultimate purpose for developing WARP was to accelerate accurate continuous energy neutron transport simulations in general 3D geometries by using GPUs.  By that metric it has been successful in its mission.  It can produce results within fractions of a percent compared to qualified and benchmarked production codes like MCNP and Serpent.  It can produce these results 11-80 times faster, depending on problem parameters and hardware.  Along the way, useful information regarding the importance of thread divergence, neutron termination, geometric acceleration structures, and dataset size has been collected and analyzed.

WARP's secondary goal of using standard nuclear data files, running in both fixed source and criticality source modes, calculating multiplication factors, and producing neutron spectra have also been achieved.  Despite these milestones, WARP can only handle a single tally volume, fixed source mode runs only marginally faster than Serpent and MCNP and produces spectra with inaccurate source values, and loading data from many isotopes has not been tested.  It also does not have routines to handle thermal scattering data or unresolved resonance tables. There is still much work to be done in testing, stabilizing WARP's execution, adding physics and features, as well as continuing to optimize algorithms for efficient GPU execution.

This initial development phase of WARP will hopefully be the first step in creating a full featured reactor simulation program that runs on GPUs.  Such an effort was needed to ensure the nuclear engineering community's codebase keeps up with modern programming techniques and hardware.  WARP is by no means a mature code ready to be used in everyday nuclear reactor calculations, but rather it is a good starting point for more advanced development.  In it's current state, it may be a good tool for multiplication factor searches, like determining reactivity coefficients by perturbing material densities and temperatures, since these types of calculations typically do not require many tallies.  WARP is also useful in a workstation environment since it currently only can be run on a single card, and can significantly acceleration calculations where only a few CPU cores would be available otherwise.  Conversely, it is currently not good for depletion calculations since they can require many, many tallies to be done.  This is not to say that GPUs couldn't perform depletion well, but rather that WARP is currently not suited to the task.

\section{Conclusions}

%Start with a brief summary of what you have accomplished (emphasis on new elements) and in what ways you have advanced the state of the art.  already done!
WARP sets itself apart from any previous endeavors in its breath of scope and its novel adaption of the event-based transport algorithm.  Previous codes have either used synthetic, simplified, and/or incomplete nuclear data.  WARP will loaded standard data files and accurately simulate each reaction type specified.  WARP will also use a flexible, scalable, and optimized geometry representation where previous studies have used simplified and restricted geometry models.  Previous works have examined event-parallel algorithms, but have not parallelized them effectively and therefore did not see the benefits of adopting such an algorithm on a GPU.  WARP will use highly-parallelized algorithms and slightly modify the original vision of the event-based algorithm to better suit execution on the GPU.  All of the previous event-based algorithms tried to implement a ``shuffle'' operation where neutron data was actually sorted into reaction-contiguous blocks \cite{nelson,tianyu_snamc}, similarly to vectorized Monte Carlo Methods developed decades ago \cite{vector,vujic_vector}.  WARP will eliminate the overhead of actually moving data by simply moving references to the data instead.  WARP also changes the unionized energy grid data format to reduce the number of data loads needed to scan cross sections.  In addition, an important part of WARP's development is also to determine if existing task-based Monte Carlo algorithms can be preserved or if they need to be modified in order to take full advantage of GPUs.

In developing WARP, a few important conclusions can be made.  The first, and arguably most important, is that running with large datasets and therefore a large number of threads is important for good performance.  It was found that in some cases, moving from $10^5$ to $10^6$ neutrons per batch in criticality mode increase performance by a factor of four or more.  It is important to keep the GPU saturated with threads so it can effectively pipeline data loads.  %WARP uses global operations to act on a large dataset of neutron histories, and there is no state continuity between kernel launches.  Therefore data must be stored in and loaded from global memory.  This makes it  important to launch as many threads as possible so the GPU can hide the large data access latencies though pipelining, especially since data access is random and non-coalesced, exacerbating the need for pipelining.  In addition to being able to hide latencies better with more active threads, using large datasets also pays for kernel launch overhead by making the computational payload large and therefore the factional cost of launching a kernel small.  This also why it is important to have most of the data loads requested immediately at the beginning of the kernel; the compute rate mainly depends on the rate at which data is fetched, so fetching it as soon as possible will provide the best performance.

The second conclusion is that remapping threads to active data is an effective way of raising the processing rate when the number of active neutrons becomes small as well as reducing thread divergence in reaction kernels.  Using a radix sort to do this is effective since it segregates reactions into contiguous blocks, efficient since it can be done in place and in $O(kN)$ time, and can eliminate completed data from being accessed if slight modifications to the standard reaction number encodings are made.  Most of the performance gain in remapping data references comes from being able to launch grids that are sized for only the active data rather than the entire dataset for both global and reaction kernels.  A non-remapping algorithm does not keep track of where active data is, and therefore must launch a grid that covers the entire dataset.  When the number of active neutrons drops below about 30\% of the initial number, the overhead and memory bandwidth cost of launching these extra threads, which only load a ``done'' bit and return, is more than the cost of performing the radix sort and edge detection.  The majority of the transport iterations occur  while there are less than 30\% of the initial neutrons left, and remapping references is usually very worthwhile.

Using the NVIDIA OptiX ray tracing framework was also shown to be an effective way to handle the geometry representation in WARP.  OptiX is flexible, and allows attachment of material and cell number to individual geometric primitives, can do perform surface detection with a randomly distributed and directed dataset, can incorporate the remapping vector created by a radix sort, and can do so fast enough to be used in WARP.  The acceleration structures that OptiX can automatically build over the scene geometry was the initial reason for using it, and it was determined that the BVH builder and traverser provided the best performance as well as using mesh primitive instancing rather than a transform node approach.  The number of objects present in the scenes is small compared to some rending scenes, and the SBVH acceleration structure actually had worse performance, presumably due to some addition overhead in traversing it which is not offset when few numbers (less than a few hundred thousand) of objects are present in the scene.  Primitive instance provides better performance since using transform nodes requires traversing a deeper geometry tree which also has more (redundant) data associated to it.

Also, assuming the capital prices for the GPU and CPU servers outlined in Table \ref{gpu_money} and the CPU code scales linearly, the capital price per Monte Carlo ``history power,'' or histories run per second, of a GPU is about 1.3-10 times that of a CPU, indicating that GPUs are a sound hardware investment for running Monte Carlo neutron transport.  Of course, this conclusion only takes the results of WARP initial development in account, i.e. simple materials and a single tally.  Determining how to main high performance when both the number of materials and tallies are increased will be part of the future development of WARP.

\section{Future Work}

The initial goals of WARP have been completed, but there is much work still to be done if it is going to become full-featured enough to be of any real use to the nuclear engineering community.  Basic functionality is currently present enough to assure the GPUs could accelerate high-fidelity Monte Carlo neutron transport calculations, which was the point of this dissertation, but many capabilities need to be expanded and ensured to scale well to large numbers of neutrons, isotopes, and geometrical zones.

The geometry is currently handled by OptiX since it provides a very convenient way to get high performance results, but its execution had to be coerced into providing WARP with the information it needed, namely the material number via the point-in-polygon algorithm.  The way OptiX executes this algorithm currently is not efficient since it must be done iteratively using OptiX's native functions instead of calculating the ordered list of intersections in a single trace.  NVIDIA is releasing ``OptiX Prime'' with OptiX 3.5, which promises to provide a more ``to the metal'' ray tracing experience, and might be leverage to provide more efficient single-traverse functionality \cite{optix3.5}.  OptiX could also be replaced by Rayforce, a high-performance GPU ray tracing library developed by VSL which has this functionality built-in and is currently available free of charge for noncommercial use \cite{rayforce}.

The geometry routines could also be replaced by handwritten routines that use combinatorial solid geometry like Serpent and MCNP.  This would make writing input for WARP more similar to what most nuclear engineers are already used to, but could more importantly provide a potential performance increase.  A universe-based CSG representation may map very well to the GPU and may even be able to fit inside of shared memory for small numbers of surfaces.  The surfaces may also be able to be bound to texture memory, which may provide a performance boost since it automatically caches for spatial locality.  Using an efficient CSG method would also lend itself to useing Woodcock delta-tracking for the neutrons and getting rid of the tracing algorithms and libraries altogether.  They account for about 50\% of execution time, and WARP's performance could be doubled by making the geometry routines more efficient.  If OptiX is determined to be the best option out of these others, however, a routine would need to be developed to automatically space coincident surfaces appropriately without specific user input.

WARP's execution can also be improved.  The amount of memory required per neutron was not kept track of in initial development, much less optimized.  Developing a function code was the main priority.  Reducing the memory needed per neutron would be very beneficial in the sense that more concurrent neutrons could be launched suing the reclaimed memory space.  Dynamic parallelism can be implemented to minimize kernel launch overhead and host-device communication in the inner transport loop.  Dynamic parallelism is a feature introduced into the NVIDA Kepler GPUs that allows kernels to be launched from kernels, and could eliminated the host having to contain the main transport loop.  Neither CUDPP or OptiX support its use, however.  CUDPP could be replaced with newer, higher-performance libraries, like CUB, which do support dynamic parallelism, but OptiX would have to be replaced by a handwritten kernel to perform the necessary geometrical tasks.  Textures could be thoroughly investigated, as they might provide better performance in some tasks, like an energy grid search on a tree structure, where their free linear interpolation and spatial caching could provide a performance boost.    Using optimized graph search libraries, like ``gunrock,'' could also be used to perform the energy grid search.

WARP also currently only supports fixed source mode in the non-remapping version as it requires popping secondary neutrons back into the active neutron pool after every iteration of the inner transport loop.  This operation is also expensive since it is a global operation that must be done often.  This algorithm could be changed to be more like a criticality run, where the primary neutrons are all transported together, then the next (smaller) generation of secondary particles are transported, then the next, and so on.  This way, the pop routine is only executed in the outer loop, and may produce faster results.   At some point, multi-GPU support should also be added so WARP can be used effectively on supercomputers with more than a one GPU present.

If an entire overhaul of the WARP transport algorithm is feasible, using a SM-based algorithm might be investigated instead of current global one.  This type of algorithm would treat each SM as an independent processor, and would provide each a bank of neutrons to transport, as is done by Liu and Henderson \cite{tianyu,henderson}.   This way, neutron data could be stored in very fast shared memory, but using this memory space would compete with storing geometrical information there.  Also, since a smaller set of neutrons could be stored, the SMs would need to communicate to determine which of the next neutrons they would take out of the global bank, or they would need to periodically rendezvous to shared source information and ensure that the distributions they use are each converged.  This type of transport algorithm would also preclude using OptiX, since it does not have SM-level functionality \cite{optix}.

Data access patterns are very important on the GPU and there are a few straight forward modifications that could be made to WARP in the future.  The first is using Legendre expansion data for the angular dependencies of anisotropic scattering instead of using tabular data.  This method uses more computation and less data than tabular distributions, and would probably perform well on the GPU.  Since global memory comes at a premium on GPUs, an on-the-fly temperature treatment for nuclides will most likely be required if more than a handful os isotopes are desired at more than on temperature.  Methods like those used in Serpent could be adapted for use on the GPU \cite{serpent}.  On-the-fly methods reduce the amount of storage needed, but they require more computation per data element loaded since the loaded value is adjusted according to the temperature of the material.  This kind of method may work well on the GPU since GPUs have a larger FLOP/byte ratio than CPUs and the additional work may cost little.  Other than the how to represent and adjust the data, an efficient way to handle situations where there are many different material and isotopes present needs to be explored.  The work done by Scudiero on porting OpenMC's macroscopic cross section processing benchmarking tool ``xsbench'' may be elucidating in this endeavor \cite{openmc,scudiero}.

%ADD:  neutron importance (cutoffs in subcritical mult), variance reduction tech, multiple tallies and reaction rates, BU
WARP would gain usability if more features were incorporated as well.  Currently, WARP treats all neutrons equally, but adding neutron weight would allow many variance reduction techniques to be implemented.  Importance cutoffs could be used to terminate secondary neutrons in fixed source runs, leading to shorter runtimes, cell importances and implicit absorption could help improve tally statistics.  Developing an efficient way to include many reaction rate tallies would also make WARP useful for performing depletion analysis.  It would also be helpful for WARP to have statistical tests like Shannon entropy to ensure the fission source is fully converged before tallies and multiplication factors are accumulated.

WARP still has some bugs, and a large part of future development will be tracking them down to ensure that accurate results are produced.  Reproducibility using the same random number seeds will also be investigated to ensure consistent results can be produced and that there are no systematic errors present in WARP.  Ensuring reproducibility will also be useful in making a test suite for WARP, so any future users can have confidence in their compilations and future developers can know their modifications do not introduce errors into WARP.

Releasing WARP as open source software is in progress and is pending University approval.  OpenMC has opened the door for open source neutron transport codes, and hopefully WARP will follow in its footsteps.  Releasing the source openly has obvious benefits of providing potential users with a convenient and transparent way of obtaining the software, as well as allowing for valuable contributions from the community.  



