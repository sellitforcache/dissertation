\chapter{Conclusions and Future Work}
\label{chap:conclusions}

The ultimate goal of WARP is to be the first 

Producing this program, which has been named WARP, will be the first step in hopefully creating a full featured reactor simulation program that runs on GPU accelerator cards.  The added value in doing this comes from the fact that many supercomputers are gaining power from GPUs and in order for nuclear engineers to take advantage of this new computing power, which they always need more of, a new code must be written to run on them.  Even though GPU computing is still in its very early stages, developing WARP hedges risk for the simulation community against their computational tools becoming under powered or even obsolete.  Conversely, it also exposes a substantial amount of  computing power that couldn't otherwise be used on personal computers, workstations, and laptops.  Targeting GPUs could enable smaller computers to take on substantial reactor simulation tasks, and potentially reduce design iterations for people without access to supercomputers.  Other than being a nod to NVIDIA's terminology, if WARP were an acronym, it would stand for ``weaving all the random particles,'' with the words ``weaving all'' referring to the lockstep way in which ``all the random particles'', i.e. the neutrons, are sorted into coherent bundles and transported.

The aim of this work is first to produce a program (WARP) that runs accurate continuous energy neutron transport simulations on the GPU in general 3D geometries using standard nuclear data files.  This program will be able to run in both fixed source and criticality source modes.  It will also be able to produce neutron spectra.  The second goal is to make these simulations as fast as possible.

\section{Conclusions}

important to keep saturated (criticality is a global quantity, using global algorithm, no state continuity between launches so must be stored in global memory, therefore very important to launch as many threads as possible to keep things pipelined and the device saturated), each history requires XXX bytes of data on top of the data required by optix, means maximum dataset size is about XXX histories on a k20 card with 5GB (assuming optix and tally memory is negligible)

low number not not saturate the gpu, not enough payload for the overhead , pipelining

\section{Future Work}

- replace geom, parallel routines with handwritten, specific ones, if geom could fit in shared memory, there would be great performance increase
- use a SM-based algorithm instead of global.  history info could be stored in shared, but would need to rendezvous.
- newer libraries, CUB, optix prime, rayforce?
- legendre instead of tabular angular?
- better geom performance with woodcock maybe
- material processing schemes
- dynamic parallelism can be implemented and kernel launch overhead minimized.  
- change fixed source pop to be more like criticaility, pop into next generation instead of this generation?
-----  might be the same as using a stack-pop and task based with syncthreads?  The only routines used in the transport loop are the geometry and the sort.   pop would replace the sort?  and pass off reactions if total coherence is wanted.  still need to communicate the fissions?  this could be eliminated by a query-able analytic representation of a converged fission source.  FFT, something else.  Might not be fast as simply using the previous cycle points but would scale well?  Previous points could be used for refinement...  might be a neat consideration?